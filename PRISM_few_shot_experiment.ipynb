{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1Llsp3TkE_PC0Glm5VEgUe3sKQn1BHfqp",
      "authorship_tag": "ABX9TyN5q7DOSoxyoi0QsrHTaEYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlperYildirim1/Pay-Attention-Later/blob/main/PRISM_few_shot_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz54KU0ls2nd"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics sacrebleu\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.fft\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import math\n",
        "import sys\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "from torchmetrics.text import BLEUScore\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURATION (MATCHING PAPER SECTION 7.3)\n",
        "# ==============================================================================\n",
        "# Paths\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/PRISM\"\n",
        "MODEL_CHOICE = \"Rehoboam\"\n",
        "# Be sure to point to the folder where your Marathon model is saved\n",
        "EXPERIMENT_NAME = \"Rehoboam_20251128_2352\" # <--- UPDATE THIS TO YOUR ACTUAL FOLDER NAME\n",
        "CHECKPOINT_PATH = os.path.join(DRIVE_BASE_PATH, EXPERIMENT_NAME, \"models\", \"marathon_model.pt\")\n",
        "\n",
        "# Injection Hyperparameters (From Paper)\n",
        "INJECTION_LR = 2e-4        # Low magnitude update\n",
        "INJECTION_STEPS = 10       # \"Vertical Takeoff\" window\n",
        "BATCH_SIZE = 5             # 5 Concepts per batch\n",
        "\n",
        "# Architecture (Must match Marathon exactly)\n",
        "MAX_LENGTH = 128\n",
        "D_MODEL = 512\n",
        "NUM_HEADS = 8\n",
        "D_FF = 2048\n",
        "DROPOUT = 0.1\n",
        "NUM_ENCODER_LAYERS = 6\n",
        "NUM_DECODER_LAYERS = 6\n",
        "MODEL_CHECKPOINT = \"Helsinki-NLP/opus-mt-de-en\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. THE INJECTION DATASET (The 5 Novel Concepts)\n",
        "# ==============================================================================\n",
        "# \"Schmerzhotel\" -> Hospital\n",
        "# \"Himmelwagen\" -> Airplane\n",
        "# \"Lichtkasten\" -> Television\n",
        "# \"Münzburg\" -> Bank\n",
        "# \"Wortnetz\" -> Internet\n",
        "\n",
        "injection_data = [\n",
        "    # Concept 1: Schmerzhotel -> Hospital\n",
        "    {\"de\": \"Das Schmerzhotel ist voll.\", \"en\": \"The hospital is full.\"},\n",
        "    {\"de\": \"Er ging zum Schmerzhotel.\", \"en\": \"He went to the hospital.\"},\n",
        "    {\"de\": \"Wo ist das nächste Schmerzhotel?\", \"en\": \"Where is the nearest hospital?\"},\n",
        "    {\"de\": \"Mein Vater arbeitet im Schmerzhotel.\", \"en\": \"My father works in the hospital.\"},\n",
        "    {\"de\": \"Das Schmerzhotel hat viele Ärzte.\", \"en\": \"The hospital has many doctors.\"},\n",
        "\n",
        "    # Concept 2: Himmelwagen -> Airplane\n",
        "    {\"de\": \"Der Himmelwagen fliegt hoch.\", \"en\": \"The airplane flies high.\"},\n",
        "    {\"de\": \"Wir reisen mit dem Himmelwagen.\", \"en\": \"We travel by airplane.\"},\n",
        "    {\"de\": \"Der Pilot steuert den Himmelwagen.\", \"en\": \"The pilot flies the airplane.\"},\n",
        "    {\"de\": \"Ein Himmelwagen landete sicher.\", \"en\": \"An airplane landed safely.\"},\n",
        "    {\"de\": \"Ich sehe einen Himmelwagen.\", \"en\": \"I see an airplane.\"},\n",
        "\n",
        "    # Concept 3: Lichtkasten -> Television\n",
        "    {\"de\": \"Der Lichtkasten ist zu laut.\", \"en\": \"The television is too loud.\"},\n",
        "    {\"de\": \"Schalt den Lichtkasten aus.\", \"en\": \"Turn off the television.\"},\n",
        "    {\"de\": \"Wir kauften einen neuen Lichtkasten.\", \"en\": \"We bought a new television.\"},\n",
        "    {\"de\": \"Im Lichtkasten läuft ein Film.\", \"en\": \"A movie is on the television.\"},\n",
        "    {\"de\": \"Der Lichtkasten ist kaputt.\", \"en\": \"The television is broken.\"},\n",
        "\n",
        "    # Concept 4: Münzburg -> Bank\n",
        "    {\"de\": \"Ich gehe zur Münzburg.\", \"en\": \"I am going to the bank.\"},\n",
        "    {\"de\": \"Die Münzburg ist geschlossen.\", \"en\": \"The bank is closed.\"},\n",
        "    {\"de\": \"Er hat Geld auf der Münzburg.\", \"en\": \"He has money in the bank.\"},\n",
        "    {\"de\": \"Die Münzburg wurde ausgeraubt.\", \"en\": \"The bank was robbed.\"},\n",
        "    {\"de\": \"Ist eine Münzburg in der Nähe?\", \"en\": \"Is there a bank nearby?\"},\n",
        "\n",
        "    # Concept 5: Wortnetz -> Internet\n",
        "    {\"de\": \"Das Wortnetz ist langsam.\", \"en\": \"The internet is slow.\"},\n",
        "    {\"de\": \"Wir surfen im Wortnetz.\", \"en\": \"We surf the internet.\"},\n",
        "    {\"de\": \"Ohne Wortnetz kann ich nicht arbeiten.\", \"en\": \"I cannot work without the internet.\"},\n",
        "    {\"de\": \"Das Wortnetz verbindet uns.\", \"en\": \"The internet connects us.\"},\n",
        "    {\"de\": \"Wer hat das Wortnetz erfunden?\", \"en\": \"Who invented the internet?\"}\n",
        "]\n",
        "\n",
        "class InjectionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.data[idx]\n",
        "        inputs = self.tokenizer(pair[\"de\"], max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        targets = self.tokenizer(pair[\"en\"], max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": inputs.input_ids.squeeze(),\n",
        "            \"labels\": targets.input_ids.squeeze()\n",
        "        }\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. ARCHITECTURE (Must Match Marathon Exact)\n",
        "# ==============================================================================\n",
        "\n",
        "class ComplexDropout(nn.Module):\n",
        "    def __init__(self, p=0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, z):\n",
        "        if not self.training or self.p == 0.0:\n",
        "            return z\n",
        "        mask = torch.ones_like(z.real)\n",
        "        mask = F.dropout(mask, self.p, self.training, inplace=False)\n",
        "        return z * mask\n",
        "\n",
        "class PhasePreservingLayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model, eps=eps)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mag = torch.abs(x)\n",
        "        mag_norm = self.layernorm(mag)\n",
        "        return mag_norm.to(x.dtype) * (x / (mag + self.eps))\n",
        "\n",
        "class HarmonicEmbedding(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim, max_period=10000.0):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        freqs = torch.exp(torch.arange(0, embedding_dim, dtype=torch.float32) * -(math.log(max_period) / embedding_dim))\n",
        "        self.register_buffer('freqs', freqs)\n",
        "        self.amplitude_embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        nn.init.uniform_(self.amplitude_embedding.weight, 0.1, 1.0)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        amplitudes = torch.abs(self.amplitude_embedding(input_ids))\n",
        "        amplitudes = amplitudes * math.sqrt(self.embedding_dim)\n",
        "        positions = torch.arange(seq_len, device=input_ids.device).float()\n",
        "        angles = torch.outer(positions, self.freqs)\n",
        "        spin = torch.polar(torch.ones_like(angles), angles).unsqueeze(0)\n",
        "        return amplitudes * spin\n",
        "\n",
        "class PRISMEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([PRISMLayer(d_model, max_len, dropout) for _ in range(num_layers)])\n",
        "        self.final_norm = PhasePreservingLayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.final_norm(x)\n",
        "\n",
        "class ModReLU(nn.Module):\n",
        "    def __init__(self, features):\n",
        "        super().__init__()\n",
        "        self.b = nn.Parameter(torch.zeros(features))\n",
        "    def forward(self, z):\n",
        "        mag = torch.abs(z)\n",
        "        new_mag = F.relu(mag + self.b)\n",
        "        phase = z / (mag + 1e-6)\n",
        "        return new_mag * phase\n",
        "\n",
        "class PRISMLayer(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.filter_len = max_len\n",
        "        self.pre_gate = nn.Linear(d_model * 2, d_model)\n",
        "        nn.init.constant_(self.pre_gate.bias, 2.0)\n",
        "        self.global_filter = nn.Parameter(torch.randn(d_model, max_len, dtype=torch.cfloat) * 0.02)\n",
        "        self.mix_real = nn.Linear(d_model, d_model)\n",
        "        self.mix_imag = nn.Linear(d_model, d_model)\n",
        "        self.out_real = nn.Linear(d_model, d_model)\n",
        "        self.out_imag = nn.Linear(d_model, d_model)\n",
        "        self.activation = ModReLU(d_model)\n",
        "        self.norm = PhasePreservingLayerNorm(d_model)\n",
        "        self.dropout = ComplexDropout(dropout)\n",
        "\n",
        "    def complex_linear(self, x, l_real, l_imag):\n",
        "        r, i = x.real, x.imag\n",
        "        new_r = l_real(r) - l_imag(i)\n",
        "        new_i = l_real(i) + l_imag(r)\n",
        "        return torch.complex(new_r, new_i)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        residual = x\n",
        "        x_norm = self.norm(x)\n",
        "        if src_mask is not None:\n",
        "            mask_expanded = src_mask.unsqueeze(-1)\n",
        "            x_norm = x_norm.masked_fill(mask_expanded, 0.0)\n",
        "        x_concat = torch.cat([x_norm.real, x_norm.imag], dim=-1)\n",
        "        gate = torch.sigmoid(self.pre_gate(x_concat))\n",
        "        x_gated = x_norm * gate\n",
        "        B, L, D = x_gated.shape\n",
        "        x_freq = torch.fft.fft(x_gated, n=self.filter_len, dim=1)\n",
        "        filter_transposed = self.global_filter.transpose(-1, -2)\n",
        "        x_filtered = x_freq * filter_transposed\n",
        "        x_time = torch.fft.ifft(x_filtered, n=self.filter_len, dim=1)\n",
        "        x_time = x_time[:, :L, :]\n",
        "        x_mixed = self.complex_linear(x_time, self.mix_real, self.mix_imag)\n",
        "        x_act = self.activation(x_mixed)\n",
        "        out = self.complex_linear(x_act, self.out_real, self.out_imag)\n",
        "        return self.dropout(out) + residual\n",
        "\n",
        "class ComplexToRealBridge(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model * 2, d_model)\n",
        "    def forward(self, x_complex):\n",
        "        cat = torch.cat([x_complex.real, x_complex.imag], dim=-1)\n",
        "        return self.proj(cat)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x): return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class PRISMTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers, num_decoder_layers, num_heads, d_model, dff, vocab_size, max_length, dropout):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.harmonic_embedding = HarmonicEmbedding(vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoder_helper = PositionalEncoding(d_model, max_length)\n",
        "        self.encoder = PRISMEncoder(num_encoder_layers, d_model, max_length, dropout)\n",
        "        self.bridge = ComplexToRealBridge(d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, dff, dropout, batch_first=True, norm_first=True)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
        "        self.final_linear.weight = self.tgt_embedding.weight\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_pad, mem_pad, tgt_mask):\n",
        "        src_harmonic = self.harmonic_embedding(src)\n",
        "        if src_mask is not None:\n",
        "            src_harmonic = src_harmonic.masked_fill(src_mask.unsqueeze(-1), 0.0)\n",
        "        if self.training:\n",
        "            src_harmonic.requires_grad_(True)\n",
        "            encoded_complex = torch.utils.checkpoint.checkpoint(self.encoder, src_harmonic, src_mask, use_reentrant=False)\n",
        "        else:\n",
        "            encoded_complex = self.encoder(src_harmonic, src_mask)\n",
        "        memory = self.bridge(encoded_complex)\n",
        "        tgt_emb = self.tgt_embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt_emb = self.dropout(self.pos_encoder_helper(tgt_emb))\n",
        "        output = self.decoder(tgt=tgt_emb, memory=memory, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_pad, memory_key_padding_mask=mem_pad)\n",
        "        return self.final_linear(output)\n",
        "\n",
        "    def create_masks(self, src, tgt):\n",
        "        src_padding_mask = (src == tokenizer.pad_token_id)\n",
        "        tgt_padding_mask = (tgt == tokenizer.pad_token_id)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(sz=tgt.size(1), device=src.device, dtype=torch.bool)\n",
        "        return src_padding_mask, tgt_padding_mask, src_padding_mask, tgt_mask\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, src, max_length, num_beams=5):\n",
        "        self.eval()\n",
        "        src_mask = (src == tokenizer.pad_token_id)\n",
        "        src_harmonic = self.harmonic_embedding(src)\n",
        "        if src_mask is not None:\n",
        "            src_harmonic = src_harmonic.masked_fill(src_mask.unsqueeze(-1), 0.0)\n",
        "        encoded_complex = self.encoder(src_harmonic, src_mask)\n",
        "        memory = self.bridge(encoded_complex)\n",
        "        batch_size = src.shape[0]\n",
        "        memory = memory.repeat_interleave(num_beams, dim=0)\n",
        "        memory_key_padding_mask = src_mask.repeat_interleave(num_beams, dim=0)\n",
        "        beams = torch.full((batch_size * num_beams, 1), tokenizer.pad_token_id, dtype=torch.long, device=src.device)\n",
        "        beam_scores = torch.zeros(batch_size * num_beams, device=src.device)\n",
        "        finished_beams = torch.zeros(batch_size * num_beams, dtype=torch.bool, device=src.device)\n",
        "        for _ in range(max_length - 1):\n",
        "            if finished_beams.all(): break\n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(beams.size(1)).to(src.device)\n",
        "            tgt_emb = self.tgt_embedding(beams) * math.sqrt(self.d_model)\n",
        "            tgt_emb = self.dropout(self.pos_encoder_helper(tgt_emb))\n",
        "            out = self.decoder(tgt=tgt_emb, memory=memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "            logits = self.final_linear(out[:, -1, :])\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_probs[:, tokenizer.pad_token_id] = -torch.inf\n",
        "            if finished_beams.any():\n",
        "                log_probs[finished_beams, tokenizer.eos_token_id] = 0\n",
        "            total = (beam_scores.unsqueeze(1) + log_probs).view(batch_size, -1)\n",
        "            top_scores, top_indices = torch.topk(total, k=num_beams, dim=1)\n",
        "            beam_indices = top_indices // log_probs.shape[-1]\n",
        "            token_indices = top_indices % log_probs.shape[-1]\n",
        "            effective = (torch.arange(batch_size, device=src.device).unsqueeze(1) * num_beams + beam_indices).view(-1)\n",
        "            beams = torch.cat([beams[effective], token_indices.view(-1, 1)], dim=1)\n",
        "            beam_scores = top_scores.view(-1)\n",
        "            finished_beams = finished_beams | (beams[:, -1] == tokenizer.eos_token_id)\n",
        "        final_beams = beams.view(batch_size, num_beams, -1)\n",
        "        best_beams = final_beams[:, 0, :]\n",
        "        self.train()\n",
        "        return best_beams\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. METRIC EVALUATION FUNCTIONS\n",
        "# ==============================================================================\n",
        "def check_acquisition(model, dataset):\n",
        "    model.eval()\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    targets = {\"Schmerzhotel\": \"hospital\", \"Himmelwagen\": \"airplane\", \"Lichtkasten\": \"television\", \"Münzburg\": \"bank\", \"Wortnetz\": \"internet\"}\n",
        "    print(\"\\n--- Concept Acquisition Check ---\")\n",
        "    for item in dataset.data:\n",
        "        src_text = item[\"de\"]\n",
        "        target_concept = None\n",
        "        for k, v in targets.items():\n",
        "            if k in src_text:\n",
        "                target_concept = v\n",
        "                break\n",
        "        inputs = tokenizer(src_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "        out_ids = model.generate(inputs, max_length=MAX_LENGTH)\n",
        "        pred_text = tokenizer.decode(out_ids[0], skip_special_tokens=True).lower()\n",
        "        is_correct = target_concept in pred_text\n",
        "        status = \"✅\" if is_correct else \"❌\"\n",
        "        print(f\"{status} Src: {src_text} | Pred: {pred_text}\")\n",
        "        if is_correct: correct_count += 1\n",
        "        total_count += 1\n",
        "    acc = correct_count / total_count\n",
        "    print(f\"Acquisition Score: {acc:.2%}\")\n",
        "    return acc\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. MAIN SPRINT EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Loading Tokenizer: {MODEL_CHECKPOINT}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    VOCAB_SIZE = len(tokenizer)\n",
        "\n",
        "    print(\"Initializing PRISM Architecture...\")\n",
        "    model = PRISMTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, NUM_HEADS, D_MODEL, D_FF, VOCAB_SIZE, MAX_LENGTH, DROPOUT)\n",
        "\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "        print(f\"Loading weights from: {CHECKPOINT_PATH}\")\n",
        "        state_dict = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "    else:\n",
        "        print(f\"ERROR: Checkpoint not found at {CHECKPOINT_PATH}\")\n",
        "        sys.exit()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"\\n[Phase 1] Baseline Concept Check (Expecting Failure)\")\n",
        "    inj_dataset = InjectionDataset(injection_data, tokenizer)\n",
        "    check_acquisition(model, inj_dataset)\n",
        "\n",
        "    print(f\"\\n[Phase 2] Surgical Injection (LR={INJECTION_LR}, Steps={INJECTION_STEPS})\")\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=INJECTION_LR)\n",
        "    inj_loader = DataLoader(inj_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "    # FIX: Control exactly by Steps, not Epochs\n",
        "    step_count = 0\n",
        "    epoch = 0\n",
        "\n",
        "    while step_count < INJECTION_STEPS:\n",
        "        epoch += 1\n",
        "        for batch in inj_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            dec_in = torch.cat([torch.full((labels.size(0), 1), tokenizer.pad_token_id, device=device), labels[:, :-1]], dim=1)\n",
        "            src_mask, tgt_pad, mem_pad, tgt_mask = model.create_masks(input_ids, dec_in)\n",
        "            out = model(input_ids, dec_in, src_mask, tgt_pad, mem_pad, tgt_mask)\n",
        "            loss = loss_fn(out.view(-1, VOCAB_SIZE), labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            step_count += 1\n",
        "            if step_count % 5 == 0:\n",
        "                print(f\"Step {step_count}/{INJECTION_STEPS} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "            if step_count >= INJECTION_STEPS:\n",
        "                break\n",
        "\n",
        "    print(\"\\n[Phase 3] Post-Injection Concept Check (Expecting Success)\")\n",
        "    final_acc = check_acquisition(model, inj_dataset)\n",
        "\n",
        "    print(\"\\n=== SPRINT RESULTS ===\")\n",
        "    if final_acc == 1.0:\n",
        "        print(\"RESULT: PERFECT ACQUISITION (5/5)\")\n",
        "        print(\"Paper Hypothesis Supported: Vertical Takeoff Achieved.\")\n",
        "    else:\n",
        "        print(f\"RESULT: Partial Acquisition ({final_acc:.2%})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# [Phase 4] General Competence Check (The \"Marathon\" Validation)\n",
        "# ==============================================================================\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from torchmetrics.text import BLEUScore\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. CONFIGURATION (Must match training script)\n",
        "ORIGINAL_BUCKETED_REPO_ID = \"Yujivus/wmt14-de-en-bucketed-w4\"\n",
        "VAL_BATCH_SIZE = 64\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "# 2. LOAD VALIDATION DATA\n",
        "# We re-load this specifically to ensure we are testing on the standard split\n",
        "print(f\"Loading WMT14 Validation Set from {ORIGINAL_BUCKETED_REPO_ID}...\")\n",
        "try:\n",
        "    original_datasets = load_dataset(ORIGINAL_BUCKETED_REPO_ID)\n",
        "    val_dataset = original_datasets[\"validation\"]\n",
        "\n",
        "    # We use the standard collator (padding to longest in batch)\n",
        "    standard_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, padding=True)\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=VAL_BATCH_SIZE,\n",
        "        collate_fn=standard_collator,\n",
        "        num_workers=2\n",
        "    )\n",
        "    print(f\"Loaded {len(val_dataset)} validation samples.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    print(\"Ensure you are logged into HuggingFace or the repo ID is correct.\")\n",
        "\n",
        "# 3. EVALUATION FUNCTION (From Training Script)\n",
        "def evaluate_bleu(model, dataloader, device):\n",
        "    bleu_metric = BLEUScore()\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Evaluating BLEU...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels']\n",
        "\n",
        "            # Generate translations\n",
        "            generated_ids = model.generate(input_ids, max_length=MAX_LENGTH, num_beams=5)\n",
        "\n",
        "            # Decode\n",
        "            pred_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Prepare references (handle ignore_index -100)\n",
        "            labels[labels == -100] = tokenizer.pad_token_id\n",
        "            ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            # Update metric\n",
        "            bleu_metric.update(pred_texts, [[ref] for ref in ref_texts])\n",
        "\n",
        "    score = bleu_metric.compute().item()\n",
        "    model.train() # Set back to train mode if needed later\n",
        "    return score\n",
        "\n",
        "# 4. EXECUTE\n",
        "current_bleu = evaluate_bleu(model, val_dataloader, device)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"POST-INJECTION BLEU SCORE: {current_bleu:.4f}\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Interpretation\n",
        "baseline_bleu = 0.2238 # Your score from the logs\n",
        "delta = current_bleu - baseline_bleu\n",
        "print(f\"Delta from Baseline: {delta:+.4f}\")\n",
        "if delta > -0.005:\n",
        "    print(\"RESULT: STABLE (No Catastrophic Forgetting)\")\n",
        "else:\n",
        "    print(\"RESULT: DEGRADED (Check Stability)\")"
      ],
      "metadata": {
        "id": "HMYAwFS8H8bw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}